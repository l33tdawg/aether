"""
Comprehensive vulnerability detection module for AetherAudit.
Implements pattern-based detection for common smart contract vulnerabilities.
"""

import re
import ast
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass


@dataclass
class VulnerabilityMatch:
    """Represents a detected vulnerability."""
    vulnerability_type: str
    severity: str
    confidence: float
    line_number: int
    description: str
    code_snippet: str
    swc_id: str = ""
    category: str = ""


class VulnerabilityDetector:
    """Comprehensive vulnerability detection using pattern matching and static analysis."""

    def __init__(self):
        self.patterns = self._initialize_patterns()
        self.contract_context = {}  # Store contract analysis context

    def set_contract_context(self, context: Dict[str, Any]):
        """Set contract analysis context for better vulnerability validation."""
        self.contract_context = context

    def _initialize_patterns(self) -> Dict[str, List[Dict[str, Any]]]:
        """Initialize vulnerability detection patterns."""
        # Get base patterns
        all_patterns = {
            'reentrancy': [
                {
                    'pattern': r'call\s*\([^)]*value[^)]*\)',
                    'description': 'External call with value transfer (potential reentrancy)',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-107',
                    'category': 'reentrancy'
                },
                {
                    'pattern': r'\.call\s*\{[^}]*value\s*:\s*[^}]*\}',
                    'description': 'Call with value parameter (reentrancy risk)',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-107',
                    'category': 'reentrancy'
                },
                {
                    'pattern': r'call\.value\s*\(',
                    'description': 'Call.value() pattern (older Solidity reentrancy)',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-107',
                    'category': 'reentrancy'
                },
                {
                    'pattern': r'send\s*\([^)]*\)\s*;',
                    'description': 'Unchecked send call (potential reentrancy)',
                    'severity': 'medium',
                    'confidence': 0.7,
                    'swc_id': 'SWC-107',
                    'category': 'reentrancy'
                }
            ],
            'access_control': [
                {
                    'pattern': r'function\s+\w+\s*\([^)]*\)\s*(public|external)?\s*\{',
                    'description': 'Function without access control modifier',
                    'severity': 'high',
                    'confidence': 0.7,
                    'swc_id': 'SWC-100',
                    'category': 'access_control',
                    'validation_function': '_validate_function_access_control'
                },
                {
                    'pattern': r'tx\.origin\s*==',
                    'description': 'Use of tx.origin for authorization (vulnerable to phishing)',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-115',
                    'category': 'access_control'
                },
                {
                    'pattern': r'selfdestruct\s*\(',
                    'description': 'Unprotected selfdestruct call',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-106',
                    'category': 'access_control'
                }
            ],
            'arithmetic': [
                {
                    'pattern': r'\+\+|\-\-|\+=|\-=|\*=|/=',
                    'description': 'Unchecked arithmetic operation',
                    'severity': 'high',
                    'confidence': 0.6,
                    'swc_id': 'SWC-101',
                    'category': 'arithmetic'
                },
                {
                    'pattern': r'balance\s*\[\s*[^]]+\s*\]\s*[\+\-\*\/]?=\s*[^;]+',
                    'description': 'Direct balance manipulation (overflow risk)',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-101',
                    'category': 'arithmetic'
                }
            ],
            'unchecked_calls': [
                {
                    'pattern': r'\.call\s*\([^)]*\)\s*;',
                    'description': 'Unchecked low-level call',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-104',
                    'category': 'unchecked_low_level_calls'
                },
                {
                    'pattern': r'\.send\s*\([^)]*\)\s*;',
                    'description': 'Unchecked send call',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-104',
                    'category': 'unchecked_low_level_calls'
                }
            ],
            'time_manipulation': [
                {
                    'pattern': r'block\.timestamp',
                    'description': 'Use of block.timestamp (miner manipulable)',
                    'severity': 'medium',
                    'confidence': 0.8,
                    'swc_id': 'SWC-116',
                    'category': 'time_manipulation'
                },
                {
                    'pattern': r'block\.number',
                    'description': 'Use of block.number (miner manipulable)',
                    'severity': 'medium',
                    'confidence': 0.7,
                    'swc_id': 'SWC-116',
                    'category': 'time_manipulation'
                }
            ],
            'gas_griefing': [
                {
                    'pattern': r'for\s*\(\s*uint\s+\w+\s*=\s*\d+\s*;\s*\w+\s*<\s*[^;]+;\s*\w+\+\+\s*\)\s*\{',
                    'description': 'Unbounded loop (potential gas griefing)',
                    'severity': 'medium',
                    'confidence': 0.7,
                    'swc_id': 'SWC-128',
                    'category': 'denial_of_service'
                }
            ],
            'tx_origin': [
                {
                    'pattern': r'tx\.origin\s*==',
                    'description': 'Use of tx.origin for authorization',
                    'severity': 'high',
                    'confidence': 0.9,
                    'swc_id': 'SWC-115',
                    'category': 'access_control'
                }
            ],
            'selfdestruct': [
                {
                    'pattern': r'selfdestruct\s*\(',
                    'description': 'Unprotected selfdestruct call',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-106',
                    'category': 'access_control'
                }
            ]
        }

        # Merge Aave-specific patterns
        aave_patterns = self._initialize_aave_specific_patterns()
        all_patterns.update(aave_patterns)

        return all_patterns

    def _initialize_aave_specific_patterns(self) -> Dict[str, List[Dict[str, Any]]]:
        """Initialize Aave-specific vulnerability patterns for high-value bug bounty hunting."""
        return {
            'flash_loan_attacks': [
                {
                    'pattern': r'flashLoan\s*\(',
                    'description': 'Flash loan function call - potential for price manipulation',
                    'severity': 'critical',
                    'confidence': 0.9,
                    'swc_id': 'SWC-999',  # Custom Aave pattern
                    'category': 'flash_loan_attack',
                    'immunefi_value': 1000000  # $1M potential
                },
                {
                    'pattern': r'executeOperation\s*\([^)]*params[^)]*\)',
                    'description': 'Flash loan executeOperation - check for state manipulation',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'flash_loan_attack',
                    'immunefi_value': 500000  # $500K potential
                }
            ],
            'liquidation_manipulation': [
                {
                    'pattern': r'liquidate\s*\([^)]*collateralAsset[^)]*debtAsset[^)]*\)',
                    'description': 'Liquidation function - check for incentive calculation exploits',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'liquidation_manipulation',
                    'immunefi_value': 500000
                },
                {
                    'pattern': r'calculateHealthFactor\s*\(',
                    'description': 'Health factor calculation - potential for manipulation',
                    'severity': 'high',
                    'confidence': 0.7,
                    'swc_id': 'SWC-999',
                    'category': 'liquidation_manipulation',
                    'immunefi_value': 300000
                }
            ],
            'oracle_manipulation': [
                {
                    'pattern': r'getAssetPrice\s*\([^)]*\)',
                    'description': 'Oracle price retrieval - check for stale price exploitation',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'oracle_manipulation',
                    'immunefi_value': 750000
                },
                {
                    'pattern': r'latestAnswer\s*\(\s*\)',
                    'description': 'Chainlink latestAnswer - check for price feed manipulation',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'oracle_manipulation',
                    'immunefi_value': 500000
                }
            ],
            'interest_rate_manipulation': [
                {
                    'pattern': r'calculateInterestRates\s*\(',
                    'description': 'Interest rate calculation - potential for manipulation',
                    'severity': 'medium',
                    'confidence': 0.7,
                    'swc_id': 'SWC-999',
                    'category': 'interest_rate_manipulation',
                    'immunefi_value': 200000
                },
                {
                    'pattern': r'accrueInterest\s*\(',
                    'description': 'Interest accrual - check for rounding exploits',
                    'severity': 'medium',
                    'confidence': 0.7,
                    'swc_id': 'SWC-999',
                    'category': 'interest_rate_manipulation',
                    'immunefi_value': 150000
                }
            ],
            'governance_attacks': [
                {
                    'pattern': r'propose\s*\([^)]*targets[^)]*values[^)]*signatures[^)]*calldatas[^)]*\)',
                    'description': 'Governance proposal - check for proposal hijacking',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'governance_attack',
                    'immunefi_value': 300000
                },
                {
                    'pattern': r'emergencyAction\s*\(',
                    'description': 'Emergency action - check for unauthorized emergency calls',
                    'severity': 'critical',
                    'confidence': 0.9,
                    'swc_id': 'SWC-999',
                    'category': 'governance_attack',
                    'immunefi_value': 1000000
                }
            ],
            'cross_chain_bridge': [
                {
                    'pattern': r'ccipReceive\s*\(',
                    'description': 'CCIP receive function - check for bridge logic vulnerabilities',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'cross_chain_bridge',
                    'immunefi_value': 500000
                },
                {
                    'pattern': r'validateMessage\s*\(',
                    'description': 'Message validation - check for cross-chain validation bypass',
                    'severity': 'high',
                    'confidence': 0.8,
                    'swc_id': 'SWC-999',
                    'category': 'cross_chain_bridge',
                    'immunefi_value': 400000
                }
            ]
        }

    def analyze_contract(self, contract_path: str, content: str) -> List[VulnerabilityMatch]:
        """
        Analyze a smart contract for vulnerabilities using pattern matching.

        Args:
            contract_path: Path to the contract file
            content: Contract source code

        Returns:
            List of detected vulnerabilities
        """
        # Set contract context for validation
        self.contract_context = {'contract_content': content, 'contract_path': contract_path}

        vulnerabilities = []

        # Split content into lines for line number tracking
        lines = content.split('\n')

        for vuln_type, patterns in self.patterns.items():
            for pattern_info in patterns:
                pattern = pattern_info['pattern']
                regex = re.compile(pattern, re.IGNORECASE | re.MULTILINE)

                for match in regex.finditer(content):
                    # Find the line number
                    line_number = content[:match.start()].count('\n') + 1

                    # Extract code snippet (current line + context)
                    start_line = max(0, line_number - 2)
                    end_line = min(len(lines), line_number + 2)
                    snippet_lines = lines[start_line:end_line]
                    code_snippet = '\n'.join(snippet_lines)

                    # Heuristic filter: avoid FP for access control when protection exists
                    if vuln_type == 'access_control' and 'Function without access control modifier' in pattern_info.get('description', ''):
                        if self._is_function_protected_heuristic(content, line_number):
                            # Skip adding this vulnerability if protection is detected
                            continue

                    vulnerability = VulnerabilityMatch(
                        vulnerability_type=vuln_type,
                        severity=pattern_info['severity'],
                        confidence=pattern_info['confidence'],
                        line_number=line_number,
                        description=pattern_info['description'],
                        code_snippet=code_snippet,
                        swc_id=pattern_info.get('swc_id', ''),
                        category=pattern_info.get('category', '')
                    )

                    vulnerabilities.append(vulnerability)

        # Apply additional analysis techniques
        vulnerabilities.extend(self._analyze_semantic_patterns(content, lines))
        vulnerabilities.extend(self._analyze_function_patterns(content, lines))

        # Debug: Print found vulnerabilities
        if vulnerabilities:
            print(f"ðŸ” Pattern detection found {len(vulnerabilities)} vulnerabilities:")
            for vuln in vulnerabilities:
                print(f"  - {vuln.vulnerability_type} at line {vuln.line_number}: {vuln.description[:50]}...")

        return vulnerabilities

    def _analyze_semantic_patterns(self, content: str, lines: List[str]) -> List[VulnerabilityMatch]:
        """Analyze semantic patterns that require more complex detection."""
        vulnerabilities = []

        # Check for missing require statements in critical functions
        critical_functions = ['withdraw', 'transfer', 'mint', 'burn']
        for func_name in critical_functions:
            if func_name in content.lower():
                # Look for function definition
                func_pattern = r'function\s+' + re.escape(func_name) + r'\s*\([^)]*\)\s*(public|external)?\s*\{'
                func_match = re.search(func_pattern, content, re.IGNORECASE)

                if func_match:
                    func_start = content[:func_match.end()].count('\n') + 1
                    # Extract a bounded slice of the function body for heuristics
                    body_slice = content[func_match.end():func_match.end()+1000]

                    # Consider protected if any of the common protections appear early in the function
                    protected_markers = [
                        'require(hasRole(',
                        'require(msg.sender ==',
                        'require(_msgSender() ==',
                        'onlyOwner',
                        'onlyGov',
                        'onlyRole',
                        'AccessControl'
                    ]
                    has_protection = any(m in body_slice for m in protected_markers) or self._has_modifier_on_signature(lines, func_start)

                    # Check if function has require statements at all
                    has_require = 'require(' in body_slice

                    if not has_require and not has_protection:
                        vulnerability = VulnerabilityMatch(
                            vulnerability_type='missing_input_validation',
                            severity='medium',
                            confidence=0.6,
                            line_number=func_start,
                            description=f'Function {func_name} lacks input validation',
                            code_snippet=lines[func_start-1] if func_start <= len(lines) else '',
                            swc_id='SWC-123',
                            category='access_control'
                        )
                        vulnerabilities.append(vulnerability)

        return vulnerabilities

    def _has_modifier_on_signature(self, lines: List[str], func_start_line: int) -> bool:
        """Check if a function signature line includes common access modifiers."""
        if 1 <= func_start_line <= len(lines):
            sig = lines[func_start_line-1]
            modifiers = ['onlyOwner', 'onlyGov', 'onlyRole', 'whenNotPaused', 'nonReentrant']
            return any(m in sig for m in modifiers)
        return False

    def _is_function_protected_heuristic(self, content: str, hit_line: int) -> bool:
        """Heuristic: determine if the matched function likely has access control.

        We look backwards for a nearby function signature and scan the signature and the
        next ~1000 chars of body for typical protection markers.
        """
        # Find approximate function start by searching backward for 'function'
        current_pos = 0
        for _ in range(hit_line):
            next_nl = content.find('\n', current_pos)
            if next_nl == -1:
                break
            current_pos = next_nl + 1
        # current_pos is start of hit_line; search backward up to 2000 chars
        scan_start = max(0, current_pos - 2000)
        segment = content[scan_start:current_pos]
        func_kw = segment.rfind('function ')
        if func_kw == -1:
            # Could not locate signature; fallback to forward-only heuristics
            func_body = content[current_pos:current_pos+1000]
            markers = ['require(hasRole(', 'require(msg.sender ==', 'require(_msgSender() ==', 'onlyOwner', 'onlyGov', 'onlyRole']
            return any(m in func_body for m in markers)

        # Signature line
        sig_start_global = scan_start + func_kw
        sig_line_start = content.rfind('\n', 0, sig_start_global)
        sig_line_end = content.find('\n', sig_start_global)
        sig_text = content[sig_line_start+1 if sig_line_start != -1 else 0 : sig_line_end if sig_line_end != -1 else sig_start_global+200]

        # Check signature modifiers
        if any(m in sig_text for m in ['onlyOwner', 'onlyGov', 'onlyRole']):
            return True

        # Scan body slice for protections
        body_start = content.find('{', sig_start_global)
        body_slice = content[body_start+1: body_start+1+1200] if body_start != -1 else content[sig_start_global:sig_start_global+1200]
        body_markers = ['require(hasRole(', 'require(msg.sender ==', 'require(_msgSender() ==', 'onlyOwner', 'onlyGov', 'onlyRole']
        return any(m in body_slice for m in body_markers)

    def _analyze_function_patterns(self, content: str, lines: List[str]) -> List[VulnerabilityMatch]:
        """Analyze function-level patterns for vulnerabilities."""
        vulnerabilities = []

        # Find all function definitions
        function_pattern = r'function\s+(\w+)\s*\([^)]*\)\s*(public|external|internal|private)?\s*(view|pure|payable)?\s*\{'
        functions = re.findall(function_pattern, content, re.IGNORECASE)

        for func_match in re.finditer(function_pattern, content, re.IGNORECASE):
            func_name = func_match.group(1)
            visibility = func_match.group(2) or 'public'  # Default visibility is public
            modifier = func_match.group(3) or ''

            func_line = content[:func_match.start()].count('\n') + 1

            # Check for dangerous function patterns
            if func_name.lower() in ['withdraw', 'transfer'] and 'payable' not in modifier.lower():
                if 'value' in content[func_match.end():func_match.end()+200]:  # Check next 200 chars
                    vulnerability = VulnerabilityMatch(
                        vulnerability_type='dangerous_payable_function',
                        severity='medium',
                        confidence=0.7,
                        line_number=func_line,
                        description=f'Function {func_name} handles value but is not payable',
                        code_snippet=lines[func_line-1] if func_line <= len(lines) else '',
                        swc_id='SWC-105',
                        category='access_control'
                    )
                    vulnerabilities.append(vulnerability)

        return vulnerabilities

    def get_vulnerability_summary(self, vulnerabilities: List[VulnerabilityMatch]) -> Dict[str, Any]:
        """Generate a summary of detected vulnerabilities."""
        summary = {
            'total_vulnerabilities': len(vulnerabilities),
            'by_severity': {
                'critical': 0,
                'high': 0,
                'medium': 0,
                'low': 0
            },
            'by_category': {},
            'by_swc': {},
            'top_issues': []
        }

        for vuln in vulnerabilities:
            # Count by severity
            summary['by_severity'][vuln.severity] += 1

            # Count by category
            category = vuln.category or 'other'
            summary['by_category'][category] = summary['by_category'].get(category, 0) + 1

            # Count by SWC ID
            if vuln.swc_id:
                summary['by_swc'][vuln.swc_id] = summary['by_swc'].get(vuln.swc_id, 0) + 1

        # Get top issues (highest confidence first)
        sorted_vulns = sorted(vulnerabilities, key=lambda x: x.confidence, reverse=True)
        summary['top_issues'] = sorted_vulns[:10]  # Top 10 issues

        return summary

    def validate_vulnerability_context(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate if a vulnerability is actually exploitable based on contract context."""
        vuln_type = vulnerability.vulnerability_type
        line_number = vulnerability.line_number

        # Context-aware validation for different vulnerability types
        if vuln_type == 'access_control':
            return self._validate_access_control(vulnerability)
        elif vuln_type == 'arithmetic':
            return self._validate_arithmetic(vulnerability)
        elif vuln_type == 'time_manipulation':
            return self._validate_time_manipulation(vulnerability)
        elif vuln_type == 'reentrancy':
            return self._validate_reentrancy(vulnerability)
        elif vuln_type == 'unchecked_calls':
            return self._validate_unchecked_calls(vulnerability)
        elif vuln_type in ['flash_loan_attack', 'liquidation_manipulation', 'oracle_manipulation', 'governance_attack', 'cross_chain_bridge']:
            return self._validate_aave_specific(vulnerability)

        # Default: keep vulnerability if confidence is high enough
        return vulnerability.confidence > 0.7

    def _validate_access_control(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate access control vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True  # Keep if we can't validate

        line_num = vulnerability.line_number

        # Check if this is in a constructor or interface (often false positives)
        lines = content.split('\n')
        if line_num <= len(lines):
            line_content = lines[line_num - 1].strip()

            # Skip constructors and interfaces
            if ('constructor' in line_content.lower() or
                'interface' in content[:line_num*50].lower() or
                'abstract' in content[:line_num*50].lower()):
                return False
            
            # Skip library functions (access control is in calling contract)
            if self._is_library_context(content, line_num):
                return False
            
            # Skip abstract/virtual functions (implementations add access control)
            if 'virtual' in line_content and ('abstract' in content[:line_num*100] or not '{' in line_content):
                return False

            # Check if function already has access control
            if self._function_has_access_control(content, line_num):
                return False

        return True
    
    def _is_library_context(self, content: str, line_number: int) -> bool:
        """Check if code is in a library rather than a contract."""
        lines = content.split('\n')
        
        # Look backwards from the line to find contract/library declaration
        for i in range(line_number - 1, max(0, line_number - 100), -1):
            if i < len(lines):
                line = lines[i].strip()
                # Found library declaration
                if re.search(r'^\s*library\s+\w+', line):
                    return True
                # Found contract declaration (not a library)
                if re.search(r'^\s*contract\s+\w+', line):
                    return False
        
        return False

    def _validate_arithmetic(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate arithmetic vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True

        line_num = vulnerability.line_number
        lines = content.split('\n')

        if line_num <= len(lines):
            line_content = lines[line_num - 1]

            # Check if using SafeMath or Solidity 0.8+
            context_before = content[:content.find(line_content)].lower()
            if ('safemath' in context_before or
                'using safemath' in context_before or
                'pragma solidity' in context_before and '>=0.8' in context_before):
                return False  # Protected by SafeMath or modern Solidity

        return True

    def _validate_time_manipulation(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate time manipulation vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True

        line_num = vulnerability.line_number
        lines = content.split('\n')

        if line_num <= len(lines):
            line_content = lines[line_num - 1]

            # Check if this is in a view/pure function (can't manipulate state)
            function_context = self._get_function_context(content, line_num)
            if function_context and ('view' in function_context or 'pure' in function_context):
                return False  # View/pure functions can't manipulate state

            # Check if timestamp is used for critical logic vs. informational
            if 'block.timestamp' in line_content:
                # If it's just for logging or non-critical logic, downgrade
                if any(keyword in line_content.lower() for keyword in ['emit', 'log', 'event']):
                    return False

        return True

    def _validate_reentrancy(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate reentrancy vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True

        line_num = vulnerability.line_number

        # Check if this is in a view/pure function
        function_context = self._get_function_context(content, line_num)
        if function_context and ('view' in function_context or 'pure' in function_context):
            return False

        # Check for reentrancy guards
        if 'nonreentrant' in content[:line_num*100].lower():
            return False

        return True

    def _validate_unchecked_calls(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate unchecked low-level call vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True

        line_num = vulnerability.line_number
        lines = content.split('\n')

        if line_num <= len(lines):
            line_content = lines[line_num - 1]

            # Check if the call result is actually checked
            # Look for patterns that check the return value
            context_after = content[line_num*50:(line_num+5)*50] if line_num < len(lines) else ""
            if (any(keyword in context_after.lower() for keyword in ['require(', 'if (!', 'assert(']) or
                '.call{' in line_content):  # Structured call with return value
                return False

        return True

    def _get_contract_content(self) -> Optional[str]:
        """Get the contract content from context."""
        # This would need to be set when calling analyze_contract
        return self.contract_context.get('contract_content')

    def _function_has_access_control(self, content: str, line_num: int) -> bool:
        """Check if a function has access control modifiers."""
        lines = content.split('\n')
        if line_num > len(lines):
            return False

        # Look backwards for function declaration
        for i in range(line_num - 1, max(0, line_num - 20), -1):
            line = lines[i].strip()
            if line.startswith('function'):
                # Check if function has modifiers
                return ('modifier' in line.lower() or
                       'onlyowner' in line.lower() or
                       'onlyadmin' in line.lower() or
                       'onlygovernance' in line.lower())
        return False

    def _get_function_context(self, content: str, line_num: int) -> Optional[str]:
        """Get the function context around a line."""
        lines = content.split('\n')
        if line_num > len(lines):
            return None

        # Look backwards for function declaration
        for i in range(line_num - 1, max(0, line_num - 10), -1):
            line = lines[i].strip()
            if line.startswith('function'):
                return line
        return None

    def filter_false_positives(self, vulnerabilities: List[VulnerabilityMatch]) -> List[VulnerabilityMatch]:
        """Filter out false positive vulnerabilities using context-aware validation."""
        filtered = []

        for vuln in vulnerabilities:
            if self.validate_vulnerability_context(vuln):
                filtered.append(vuln)
            else:
                # Downgrade confidence for filtered vulnerabilities
                vuln.confidence = max(0.1, vuln.confidence * 0.3)

        return filtered

    def enhance_with_ml_analysis(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> List[VulnerabilityMatch]:
        """Enhance vulnerability detection using machine learning patterns."""
        try:
            from core.ml_analyzer import MLAnalyzer

            ml_analyzer = MLAnalyzer()
            enhanced_vulns = []

            for vuln in vulnerabilities:
                # Convert to dict for ML analysis
                vuln_dict = {
                    'vulnerability_type': vuln.vulnerability_type,
                    'severity': vuln.severity,
                    'confidence': vuln.confidence,
                    'line': vuln.line_number,
                    'description': vuln.description,
                    'code_snippet': vuln.code_snippet,
                    'swc_id': vuln.swc_id,
                    'category': vuln.category,
                    'tool': 'pattern_analyzer',
                    'status': 'suspected'
                }

                # Get ML enhancement
                contract_features = self._extract_contract_features_for_ml(contract_content, vuln_dict)
                ml_prediction = ml_analyzer.predict_vulnerability_confidence(
                    vuln.vulnerability_type,
                    contract_features
                )

                # Apply ML enhancements
                if ml_prediction['pattern_match']:
                    vuln.confidence = max(vuln.confidence, ml_prediction['confidence'])
                    vuln.severity = self._upgrade_severity_with_ml(vuln.severity, ml_prediction)

                    # Add ML insights
                    vuln.ml_enhanced = True
                    vuln.historical_success_rate = ml_prediction['historical_success_rate']
                    vuln.expected_funds_at_risk = ml_prediction['expected_funds_at_risk']

                enhanced_vulns.append(vuln)

            return enhanced_vulns

        except ImportError:
            print("âš ï¸ ML Analyzer not available, skipping ML enhancement")
            return vulnerabilities
        except Exception as e:
            print(f"Error in ML enhancement: {e}")
            return vulnerabilities

    def _extract_contract_features_for_ml(self, contract_content: str, vulnerability: Dict[str, Any]) -> Dict[str, Any]:
        """Extract contract features for ML analysis."""
        vuln_type = vulnerability.get('vulnerability_type', '')
        line_num = vulnerability.get('line', 0)

        # Use the same feature extraction logic as in MLAnalyzer
        if vuln_type == 'reentrancy':
            return self._extract_reentrancy_features(contract_content, line_num)
        elif vuln_type == 'access_control':
            return self._extract_access_control_features(contract_content, line_num)
        elif vuln_type == 'oracle_manipulation':
            return self._extract_oracle_features(contract_content, line_num)
        elif vuln_type == 'flash_loan_attack':
            return self._extract_flash_loan_features(contract_content, line_num)
        else:
            return self._extract_generic_features(contract_content, line_num)

    def _upgrade_severity_with_ml(self, current_severity: str, ml_prediction: Dict[str, float]) -> str:
        """Upgrade severity based on ML insights."""
        if ml_prediction['confidence'] > 0.8 and ml_prediction['historical_success_rate'] > 0.7:
            if current_severity == 'medium':
                return 'high'
            elif current_severity == 'low':
                return 'medium'

        return current_severity

    def assess_economic_impact(self, vulnerabilities: List[VulnerabilityMatch]) -> Dict[str, Any]:
        """Assess economic impact of vulnerabilities for Immunefi bounty assessment."""
        impact_summary = {
            'total_funds_at_risk': 0,
            'critical_vulnerabilities': 0,
            'high_vulnerabilities': 0,
            'medium_vulnerabilities': 0,
            'low_vulnerabilities': 0,
            'immunefi_eligible_count': 0,
            'max_potential_bounty': 0,
            'vulnerability_breakdown': {}
        }

        for vuln in vulnerabilities:
            vuln_type = vuln.vulnerability_type
            severity = vuln.severity

            # Count by severity
            if severity == 'critical':
                impact_summary['critical_vulnerabilities'] += 1
                impact_summary['immunefi_eligible_count'] += 1
            elif severity == 'high':
                impact_summary['high_vulnerabilities'] += 1
                impact_summary['immunefi_eligible_count'] += 1
            elif severity == 'medium':
                impact_summary['medium_vulnerabilities'] += 1
            elif severity == 'low':
                impact_summary['low_vulnerabilities'] += 1

            # Calculate economic impact based on vulnerability type
            economic_impact = self._calculate_vulnerability_impact(vuln)

            # Update totals
            impact_summary['total_funds_at_risk'] += economic_impact['funds_at_risk']
            impact_summary['max_potential_bounty'] += economic_impact['bounty_potential']

            # Track by vulnerability type
            if vuln_type not in impact_summary['vulnerability_breakdown']:
                impact_summary['vulnerability_breakdown'][vuln_type] = {
                    'count': 0,
                    'funds_at_risk': 0,
                    'bounty_potential': 0
                }

            impact_summary['vulnerability_breakdown'][vuln_type]['count'] += 1
            impact_summary['vulnerability_breakdown'][vuln_type]['funds_at_risk'] += economic_impact['funds_at_risk']
            impact_summary['vulnerability_breakdown'][vuln_type]['bounty_potential'] += economic_impact['bounty_potential']

        return impact_summary

    def _calculate_vulnerability_impact(self, vulnerability: VulnerabilityMatch) -> Dict[str, float]:
        """Calculate economic impact of a specific vulnerability."""
        vuln_type = vulnerability.vulnerability_type
        severity = vulnerability.severity

        # Base impact calculations
        if severity == 'critical':
            base_funds = 1000000  # $1M base for critical
        elif severity == 'high':
            base_funds = 100000   # $100K base for high
        elif severity == 'medium':
            base_funds = 10000    # $10K base for medium
        else:
            base_funds = 1000     # $1K base for low

        # Adjust based on vulnerability type for Aave-specific scenarios
        multiplier = 1.0

        if vuln_type == 'flash_loan_attack':
            multiplier = 3.0  # Flash loans can manipulate large amounts
        elif vuln_type == 'liquidation_manipulation':
            multiplier = 2.5  # Liquidations affect protocol health
        elif vuln_type == 'oracle_manipulation':
            multiplier = 2.0  # Oracles control pricing across protocol
        elif vuln_type == 'governance_attack':
            multiplier = 2.0  # Governance controls entire protocol
        elif vuln_type == 'cross_chain_bridge':
            multiplier = 1.5  # Bridge issues affect cross-chain assets

        funds_at_risk = base_funds * multiplier

        # Calculate Immunefi bounty potential (10% of funds at risk, capped)
        if severity == 'critical':
            bounty_potential = min(funds_at_risk * 0.1, 1000000)  # Cap at $1M
        elif severity == 'high':
            bounty_potential = min(funds_at_risk * 0.1, 75000)   # Cap at $75K
        elif severity == 'medium':
            bounty_potential = min(funds_at_risk * 0.1, 10000)   # Cap at $10K
        else:
            bounty_potential = min(funds_at_risk * 0.1, 1000)    # Cap at $1K

        return {
            'funds_at_risk': funds_at_risk,
            'bounty_potential': bounty_potential
        }

    def analyze_state_machine_exploits(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> List[Dict[str, Any]]:
        """Analyze for multi-transaction exploit chains and state-dependent vulnerabilities."""
        state_exploits = []

        # Group vulnerabilities by contract and function context
        vuln_groups = self._group_vulnerabilities_by_context(vulnerabilities)

        for context_key, context_vulns in vuln_groups.items():
            if len(context_vulns) >= 2:  # Need at least 2 vulnerabilities for multi-transaction exploits
                # Check for state-dependent exploit chains
                exploit_chain = self._analyze_exploit_chain(context_vulns, contract_content)
                if exploit_chain:
                    state_exploits.append(exploit_chain)

        return state_exploits

    def _group_vulnerabilities_by_context(self, vulnerabilities: List[VulnerabilityMatch]) -> Dict[str, List[VulnerabilityMatch]]:
        """Group vulnerabilities by contract function context."""
        groups = {}

        for vuln in vulnerabilities:
            # Create context key based on function and vulnerability type
            context_key = f"{vuln.vulnerability_type}_{vuln.line_number}"
            if context_key not in groups:
                groups[context_key] = []
            groups[context_key].append(vuln)

        return groups

    def _analyze_exploit_chain(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> Optional[Dict[str, Any]]:
        """Analyze if vulnerabilities can be chained into a multi-transaction exploit."""
        if len(vulnerabilities) < 2:
            return None

        # Look for specific exploit patterns
        vuln_types = [v.vulnerability_type for v in vulnerabilities]

        # Flash loan + Oracle manipulation chain
        if 'flash_loan_attack' in vuln_types and 'oracle_manipulation' in vuln_types:
            return self._analyze_flash_loan_oracle_chain(vulnerabilities, contract_content)

        # Liquidation + Interest rate manipulation chain
        elif 'liquidation_manipulation' in vuln_types and 'interest_rate_manipulation' in vuln_types:
            return self._analyze_liquidation_interest_chain(vulnerabilities, contract_content)

        # Governance + Access control chain
        elif 'governance_attack' in vuln_types and 'access_control' in vuln_types:
            return self._analyze_governance_access_chain(vulnerabilities, contract_content)

        return None

    def _analyze_flash_loan_oracle_chain(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> Dict[str, Any]:
        """Analyze flash loan + oracle manipulation exploit chain."""
        return {
            'exploit_type': 'flash_loan_oracle_manipulation',
            'severity': 'critical',
            'description': 'Flash loan can be used to manipulate oracle prices for profitable liquidations',
            'steps': [
                '1. Deploy flash loan contract',
                '2. Borrow large amount via flash loan',
                '3. Manipulate oracle price using borrowed funds',
                '4. Trigger liquidations at manipulated price',
                '5. Repay flash loan and keep profits'
            ],
            'funds_at_risk': 2000000,  # $2M potential
            'bounty_potential': 200000,  # $200K potential bounty
            'vulnerabilities_involved': [v.vulnerability_type for v in vulnerabilities]
        }

    def _analyze_liquidation_interest_chain(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> Dict[str, Any]:
        """Analyze liquidation + interest rate manipulation exploit chain."""
        return {
            'exploit_type': 'liquidation_interest_manipulation',
            'severity': 'high',
            'description': 'Interest rate manipulation can force unwanted liquidations',
            'steps': [
                '1. Manipulate interest rates to increase borrowing costs',
                '2. Force users into liquidation threshold',
                '3. Execute liquidation with manipulated incentives',
                '4. Profit from liquidation bonus'
            ],
            'funds_at_risk': 500000,  # $500K potential
            'bounty_potential': 50000,  # $50K potential bounty
            'vulnerabilities_involved': [v.vulnerability_type for v in vulnerabilities]
        }

    def _analyze_governance_access_chain(self, vulnerabilities: List[VulnerabilityMatch], contract_content: str) -> Dict[str, Any]:
        """Analyze governance + access control exploit chain."""
        return {
            'exploit_type': 'governance_access_bypass',
            'severity': 'critical',
            'description': 'Access control bypass can lead to governance manipulation',
            'steps': [
                '1. Bypass access control to gain unauthorized access',
                '2. Propose malicious governance changes',
                '3. Execute governance attack',
                '4. Control protocol parameters'
            ],
            'funds_at_risk': 1000000,  # $1M potential
            'bounty_potential': 100000,  # $100K potential bounty
            'vulnerabilities_involved': [v.vulnerability_type for v in vulnerabilities]
        }

    def _validate_aave_specific(self, vulnerability: VulnerabilityMatch) -> bool:
        """Validate Aave-specific vulnerabilities."""
        content = self._get_contract_content()
        if not content:
            return True  # Keep if we can't validate

        vuln_type = vulnerability.vulnerability_type
        line_num = vulnerability.line_number
        lines = content.split('\n')

        if line_num <= len(lines):
            line_content = lines[line_num - 1]

            # Flash loan validation
            if vuln_type == 'flash_loan_attack':
                # Check if flash loan has proper validation
                if 'require' not in content[max(0, line_num-10):line_num+10]:
                    return False  # No validation, likely false positive

                # Check for executeOperation implementation
                if 'executeOperation' in line_content and 'require' in content[line_num:line_num+20]:
                    return True  # Proper validation exists

            # Liquidation validation
            elif vuln_type == 'liquidation_manipulation':
                # Check if liquidation has proper checks
                context_before = content[max(0, line_num-20):line_num]
                if any(keyword in context_before for keyword in ['require', 'if (', 'modifier']):
                    return True  # Proper validation exists

            # Oracle validation
            elif vuln_type == 'oracle_manipulation':
                # Check for oracle validation patterns
                context_after = content[line_num:min(len(lines), line_num+10)]
                if any(keyword in context_after for keyword in ['require', 'assert', 'if (']):
                    return False  # Oracle calls are validated

            # Governance validation
            elif vuln_type == 'governance_attack':
                # Check for governance validation
                if 'onlyGovernance' in content or 'onlyOwner' in content or 'require' in line_content:
                    return False  # Proper access control exists

            # Cross-chain validation
            elif vuln_type == 'cross_chain_bridge':
                # Check for proper message validation
                if 'validateMessage' in line_content and 'require' in content[line_num:line_num+15]:
                    return False  # Proper validation exists

        return True


class SlitherIntegration:
    """Integration with Slither static analyzer with database-backed caching."""

    def __init__(self, database_manager=None):
        self.slither_available = self._check_slither_availability()
        self.database = database_manager
        if self.database is None:
            # Initialize database if not provided
            try:
                from core.database_manager import DatabaseManager
                self.database = DatabaseManager()
            except:
                self.database = None  # Gracefully handle missing database

    def _check_slither_availability(self) -> bool:
        """Check if Slither is available and working."""
        try:
            import os
            import shutil
            import subprocess
            
            # First, check if slither is in PATH
            slither_path = shutil.which('slither')
            if slither_path and os.path.exists(slither_path):
                # Try to run it to verify it works
                try:
                    result = subprocess.run(
                        ['slither', '--version'],
                        capture_output=True,
                        timeout=5,
                        text=True
                    )
                    if result.returncode == 0:
                        return True
                except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
                    pass
            
            # Check for slither in current project's venv
            current_dir = os.getcwd()
            venv_slither = os.path.join(current_dir, 'venv', 'bin', 'slither')
            if os.path.exists(venv_slither):
                try:
                    result = subprocess.run(
                        [venv_slither, '--version'],
                        capture_output=True,
                        timeout=5,
                        text=True
                    )
                    if result.returncode == 0:
                        return True
                except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
                    pass
            
            # Check for slither in common venv locations relative to current project
            project_root = current_dir
            for _ in range(5):  # Search up 5 levels
                venv_path = os.path.join(project_root, 'venv', 'bin', 'slither')
                if os.path.exists(venv_path):
                    try:
                        result = subprocess.run(
                            [venv_path, '--version'],
                            capture_output=True,
                            timeout=5,
                            text=True
                        )
                        if result.returncode == 0:
                            return True
                    except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
                        pass
                
                parent = os.path.dirname(project_root)
                if parent == project_root:  # Reached filesystem root
                    break
                project_root = parent
            
            return False
        except Exception:
            return False

    def _analyze_with_slither_api(self, contract_path: str) -> List[Dict[str, Any]]:
        """Try to analyze using Slither's Python API."""
        # Skip API approach due to SIP issues - use CLI only
        return None

    def analyze_with_slither(self, contract_path: str) -> List[Dict[str, Any]]:
        """Run Slither analysis on a contract using CLI with database-backed caching."""
        if not self.slither_available:
            return []

        try:
            import os
            from datetime import datetime, timedelta
            
            # Detect project root for caching
            contract_dir = os.path.dirname(os.path.abspath(contract_path))
            project_root = self._find_project_root(contract_dir)
            
            if not project_root:
                # No project structure found, analyze individual file
                return self._analyze_with_slither_cli(contract_path, None)
            
            # Check database cache first
            if self.database:
                cached = self.database.get_slither_cache(project_root)
                if cached:
                    cache_age_hours = (datetime.now().timestamp() - cached['analyzed_at']) / 3600
                    print(f"      â™»ï¸  Using cached Slither results (analyzed {cache_age_hours:.1f}h ago)", flush=True)
                    
                    # Filter for this specific contract
                    contract_basename = os.path.basename(contract_path)
                    filtered = [
                        f for f in cached['findings'] 
                        if contract_basename in f.get('description', '') or 
                           contract_basename in str(f.get('elements', []))
                    ]
                    
                    if filtered:
                        # Count findings by severity
                        severity_counts = {}
                        type_counts = {}
                        
                        # Debug: Check first finding structure (temporary debug)
                        if len(filtered) > 0:
                            print(f"      [DEBUG] First finding sample: type={filtered[0].get('type', 'MISSING')}, severity={filtered[0].get('severity', 'MISSING')}, keys={list(filtered[0].keys())[:5]}", flush=True)
                        
                        for finding in filtered:
                            # Try both 'severity' and 'impact' keys for backwards compatibility
                            severity = finding.get('severity', finding.get('impact', 'unknown')).lower()
                            # Try both 'type' and 'check_id' keys for backwards compatibility
                            vuln_type = finding.get('type', finding.get('check_id', 'unknown'))
                            severity_counts[severity] = severity_counts.get(severity, 0) + 1
                            type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1
                        
                        # Print detailed breakdown
                        print(f"      ðŸ” Found {len(filtered)} Slither findings for {contract_basename}:", flush=True)
                        for severity in ['critical', 'high', 'medium', 'low', 'informational', 'unknown']:
                            if severity in severity_counts:
                                print(f"         - {severity.capitalize()}: {severity_counts[severity]}", flush=True)
                        
                        # Print top vulnerability types if any
                        if type_counts:
                            top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                            print(f"         Top types: {', '.join([f'{vtype}({count})' for vtype, count in top_types])}", flush=True)
                    else:
                        print(f"      âœ… No Slither findings for {contract_basename}", flush=True)
                    
                    return filtered
            
            # No cache found - run full analysis on project
            print(f"      ðŸ†• First analysis of this project - running Slither...", flush=True)
            findings = self._analyze_with_slither_cli(contract_path, project_root)
            
            # Display findings summary immediately after analysis
            if findings:
                severity_counts = {}
                type_counts = {}
                for finding in findings:
                    severity = finding.get('severity', 'unknown').lower()
                    vuln_type = finding.get('type', 'unknown')
                    severity_counts[severity] = severity_counts.get(severity, 0) + 1
                    type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1
                
                # Print detailed breakdown of found issues
                print(f"      ðŸ“Š Slither analysis found {len(findings)} issues:", flush=True)
                for severity in ['critical', 'high', 'medium', 'low', 'informational', 'unknown']:
                    if severity in severity_counts:
                        print(f"         - {severity.capitalize()}: {severity_counts[severity]}", flush=True)
                
                # Print top vulnerability types
                if type_counts:
                    top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                    print(f"         Top types: {', '.join([f'{vtype}({count})' for vtype, count in top_types])}", flush=True)
            
            # Save to database cache
            if self.database and project_root and findings:
                # Determine framework
                framework = None
                if os.path.exists(os.path.join(project_root, 'foundry.toml')):
                    framework = 'foundry'
                elif os.path.exists(os.path.join(project_root, 'hardhat.config.ts')) or \
                     os.path.exists(os.path.join(project_root, 'hardhat.config.js')):
                    framework = 'hardhat'
                elif os.path.exists(os.path.join(project_root, 'truffle-config.js')):
                    framework = 'truffle'
                
                self.database.save_slither_cache(project_root, findings, framework)
                print(f"      ðŸ’¾ Cached {len(findings)} Slither findings for future audits", flush=True)
            
            # Filter for current contract
            contract_basename = os.path.basename(contract_path)
            filtered = [
                f for f in findings 
                if contract_basename in f.get('description', '') or 
                   contract_basename in str(f.get('elements', []))
            ]
            
            return filtered

        except Exception as e:
            import logging
            logging.debug(f"Slither analysis failed: {e}")
            # Don't crash - let other analysis methods handle it
            return []
    
    def _find_project_root(self, start_dir: str) -> Optional[str]:
        """Find the project root directory by looking for config files."""
        import os
        search_dir = start_dir
        for _ in range(10):  # Search up 10 levels
            if os.path.exists(os.path.join(search_dir, 'foundry.toml')):
                return search_dir
            if os.path.exists(os.path.join(search_dir, 'hardhat.config.ts')) or \
               os.path.exists(os.path.join(search_dir, 'hardhat.config.js')):
                return search_dir
            if os.path.exists(os.path.join(search_dir, 'truffle-config.js')):
                return search_dir
            parent = os.path.dirname(search_dir)
            if parent == search_dir:  # Reached filesystem root
                break
            search_dir = parent
        return None
    
    def _get_required_node_version(self, project_root: Optional[str]) -> Optional[str]:
        """Get required Node.js version from .nvmrc file."""
        import os
        if not project_root:
            return None
        
        nvmrc_path = os.path.join(project_root, '.nvmrc')
        if os.path.exists(nvmrc_path):
            try:
                with open(nvmrc_path, 'r') as f:
                    version = f.read().strip().lstrip('v')
                    return version
            except Exception:
                pass
        return None
    
    def _check_node_version_available(self, version: str) -> bool:
        """Check if a specific Node.js version is installed via NVM."""
        import os
        nvm_node_path = os.path.expanduser(f"~/.nvm/versions/node/v{version}")
        return os.path.exists(nvm_node_path)
    
    def _get_node_version_in_env(self, env: dict) -> Optional[str]:
        """Get the Node.js version that would be used with the given environment."""
        import subprocess
        try:
            result = subprocess.run(
                ['node', '--version'],
                capture_output=True,
                text=True,
                timeout=5,
                env=env
            )
            if result.returncode == 0:
                # Output is like "v24.6.0", strip the 'v'
                return result.stdout.strip().lstrip('v')
        except Exception:
            pass
        return None
    
    def _preflight_check_nodejs(self, framework: str, required_version: Optional[str], project_root: Optional[str]) -> Dict[str, Any]:
        """
        Pre-flight check for Node.js availability and compatibility.
        
        Returns dict with:
        - success: bool
        - error: str (if success=False)
        - message: str (if success=True)
        - auto_fixable: bool
        - hints: List[str]
        """
        import os
        
        # Minimum versions required by frameworks
        MIN_VERSIONS = {
            'hardhat': '22.10.0',
            'truffle': '18.0.0'
        }
        
        min_version = MIN_VERSIONS.get(framework)
        if not min_version:
            return {'success': True}
        
        # Check if required version from .nvmrc is available
        if required_version:
            if self._check_node_version_available(required_version):
                return {
                    'success': True,
                    'message': f"Node.js v{required_version} available (from .nvmrc)"
                }
            else:
                return {
                    'success': False,
                    'error': f"Required Node.js v{required_version} not installed",
                    'auto_fixable': True,
                    'hints': [
                        f"Project requires Node.js v{required_version} (specified in .nvmrc)",
                        f"Will attempt to install: nvm install {required_version}"
                    ]
                }
        
        # No .nvmrc - check if we have any compatible version
        nvm_versions_dir = os.path.expanduser("~/.nvm/versions/node")
        if not os.path.exists(nvm_versions_dir):
            return {
                'success': False,
                'error': "NVM not found or no Node.js versions installed",
                'auto_fixable': False,
                'hints': [
                    "Install NVM: curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash",
                    f"Then install Node.js: nvm install {min_version}"
                ]
            }
        
        # Find any compatible version
        import glob
        all_versions = glob.glob(os.path.join(nvm_versions_dir, "v*"))
        compatible_versions = []
        
        for ver_path in all_versions:
            ver = os.path.basename(ver_path).lstrip('v')
            try:
                ver_parts = [int(x) for x in ver.split('.')]
                min_parts = [int(x) for x in min_version.split('.')]
                
                if ver_parts >= min_parts:
                    compatible_versions.append(ver)
            except (ValueError, IndexError):
                continue
        
        if compatible_versions:
            latest = sorted(compatible_versions)[-1]
            return {
                'success': True,
                'message': f"Compatible Node.js v{latest} available"
            }
        
        # No compatible version found
        return {
            'success': False,
            'error': f"No compatible Node.js version found (need >= {min_version})",
            'auto_fixable': True,
            'hints': [
                f"{framework.capitalize()} requires Node.js >= {min_version}",
                f"Will attempt to install recommended version"
            ]
        }
    
    def _auto_fix_nodejs_version(self, required_version: Optional[str]) -> Dict[str, Any]:
        """
        Attempt to automatically install the required Node.js version.
        
        Returns dict with:
        - success: bool
        - message: str (if success=True)
        - error: str (if success=False)
        """
        import subprocess
        
        # Determine version to install
        version_to_install = required_version or '24.6.0'  # Default to LTS
        
        print(f"      ðŸ“¦ Installing Node.js v{version_to_install}...", flush=True)
        
        try:
            # Run nvm install
            result = subprocess.run(
                ['bash', '-c', f'source ~/.nvm/nvm.sh && nvm install {version_to_install}'],
                capture_output=True,
                text=True,
                timeout=300  # 5 minutes max for download and install
            )
            
            if result.returncode == 0:
                return {
                    'success': True,
                    'message': f"Successfully installed Node.js v{version_to_install}"
                }
            else:
                return {
                    'success': False,
                    'error': f"Failed to install Node.js: {result.stderr[:200]}"
                }
        
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': "Installation timed out after 5 minutes"
            }
        except Exception as e:
            return {
                'success': False,
                'error': f"Installation failed: {str(e)}"
            }

    def _analyze_with_slither_cli(self, contract_path: str, project_root: Optional[str] = None) -> List[Dict[str, Any]]:
        """Run Slither analysis on a contract using CLI."""
        try:
            import subprocess
            import json
            import os
            import re
            import tempfile
            import time
            from datetime import datetime

            # Extract pragma version from contract
            solc_binary = None
            with open(contract_path, 'r') as f:
                content = f.read()
                pragma_match = re.search(r'pragma\s+solidity\s+([^;]+);', content)
                if pragma_match:
                    pragma_str = pragma_match.group(1).strip()
                    # Extract version: ^0.4.19 -> 0.4.19
                    version_match = re.search(r'(\d+\.\d+\.\d+)', pragma_str)
                    if version_match:
                        solc_version = version_match.group(1)
                        # Try to find the solcx binary for this version
                        solcx_path = os.path.expanduser(f"~/.solcx/solc-v{solc_version}")
                        if os.path.exists(solcx_path):
                            solc_binary = solcx_path

            # Setup environment with Foundry in PATH and correct Node version from NVM
            env = os.environ.copy()
            foundry_bin = os.path.expanduser("~/.foundry/bin")
            if foundry_bin not in env.get('PATH', ''):
                env['PATH'] = f"{foundry_bin}:{env.get('PATH', '')}"
            
            # Add Node from NVM - use project's required version or find a compatible one
            node_version_to_use = None
            if project_root:
                required_version = self._get_required_node_version(project_root)
                if required_version and self._check_node_version_available(required_version):
                    node_version_to_use = required_version
            
            # If no specific version found, try to find a compatible version
            if not node_version_to_use:
                nvm_versions_dir = os.path.expanduser("~/.nvm/versions/node")
                if os.path.exists(nvm_versions_dir):
                    import glob
                    # Prefer v24.x or v22.x for modern compatibility
                    for major_version in ['24', '22', '20']:
                        node_versions = glob.glob(os.path.join(nvm_versions_dir, f"v{major_version}.*"))
                        if node_versions:
                            latest = sorted(node_versions)[-1]
                            node_version_to_use = os.path.basename(latest).lstrip('v')
                            break
            
            # Set the Node.js version in PATH
            if node_version_to_use:
                nvm_node_bin = os.path.expanduser(f"~/.nvm/versions/node/v{node_version_to_use}/bin")
                if os.path.exists(nvm_node_bin):
                    env['PATH'] = f"{nvm_node_bin}:{env.get('PATH', '')}"

            # Find slither command - check PATH first, then venv locations
            slither_cmd = None
            import shutil
            
            # First, check if slither is in PATH
            slither_path = shutil.which('slither')
            if slither_path and os.path.exists(slither_path):
                slither_cmd = 'slither'  # Use from PATH
            
            # If not in PATH, check current project's venv
            current_dir = os.getcwd()
            if not slither_cmd:
                venv_slither = os.path.join(current_dir, 'venv', 'bin', 'slither')
                if os.path.exists(venv_slither):
                    slither_cmd = venv_slither
            
            # If still not found, search up directory tree for venv
            if not slither_cmd:
                project_root = current_dir
                for _ in range(5):  # Search up 5 levels
                    venv_path = os.path.join(project_root, 'venv', 'bin', 'slither')
                    if os.path.exists(venv_path):
                        slither_cmd = venv_path
                        break
                    
                    parent = os.path.dirname(project_root)
                    if parent == project_root:  # Reached filesystem root
                        break
                    project_root = parent
            
            # Final fallback to 'slither' command (will use PATH)
            if not slither_cmd:
                slither_cmd = 'slither'

            # Detect build system if we don't have project_root
            build_framework = None
            has_artifacts = False  # Track if project has pre-compiled artifacts
            if not project_root:
                contract_dir = os.path.dirname(os.path.abspath(contract_path))
                search_dir = contract_dir
                
                for _ in range(10):  # Search up 10 levels
                    # Check for Foundry
                    if os.path.exists(os.path.join(search_dir, 'foundry.toml')):
                        build_framework = 'foundry'
                        project_root = search_dir
                        break
                    # Check for Hardhat
                    if os.path.exists(os.path.join(search_dir, 'hardhat.config.ts')) or \
                       os.path.exists(os.path.join(search_dir, 'hardhat.config.js')):
                        build_framework = 'hardhat'
                        project_root = search_dir
                        break
                    # Check for Truffle
                    if os.path.exists(os.path.join(search_dir, 'truffle-config.js')):
                        build_framework = 'truffle'
                        project_root = search_dir
                        break
                        
                    parent = os.path.dirname(search_dir)
                    if parent == search_dir:  # Reached filesystem root
                        break
                    search_dir = parent
            else:
                # Determine framework from project_root
                if os.path.exists(os.path.join(project_root, 'foundry.toml')):
                    build_framework = 'foundry'
                elif os.path.exists(os.path.join(project_root, 'hardhat.config.ts')) or \
                     os.path.exists(os.path.join(project_root, 'hardhat.config.js')):
                    build_framework = 'hardhat'
                elif os.path.exists(os.path.join(project_root, 'truffle-config.js')):
                    build_framework = 'truffle'

            # Create log file for detailed output
            log_dir = os.path.join(os.getcwd(), 'cache')
            os.makedirs(log_dir, exist_ok=True)
            log_file = os.path.join(log_dir, f'slither_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
            
            # For framework-based projects (Foundry/Hardhat/Truffle), Slither needs the project root
            # For standalone contracts, use the contract file directly
            if build_framework in ['hardhat', 'truffle', 'foundry'] and project_root:
                # Pre-flight check: Validate Node.js version for Hardhat/Truffle projects
                if build_framework in ['hardhat', 'truffle']:
                    required_node_version = self._get_required_node_version(project_root)
                    node_check_result = self._preflight_check_nodejs(build_framework, required_node_version, project_root)
                    
                    if not node_check_result['success']:
                        print(f"      âŒ Node.js pre-flight check failed: {node_check_result['error']}", flush=True)
                        if node_check_result.get('auto_fixable'):
                            print(f"      ðŸ”§ Attempting to auto-fix...", flush=True)
                            fix_result = self._auto_fix_nodejs_version(required_node_version)
                            if fix_result['success']:
                                print(f"      âœ… {fix_result['message']}", flush=True)
                            else:
                                print(f"      âš ï¸  Auto-fix failed: {fix_result['error']}", flush=True)
                                for hint in node_check_result.get('hints', []):
                                    print(f"      ðŸ’¡ {hint}", flush=True)
                                return []
                        else:
                            for hint in node_check_result.get('hints', []):
                                print(f"      ðŸ’¡ {hint}", flush=True)
                            return []
                    elif node_check_result.get('message'):
                        print(f"      âœ… {node_check_result['message']}", flush=True)
                
                # Check if dependencies are installed for npm-based frameworks
                if build_framework in ['hardhat', 'truffle']:
                    node_modules_path = os.path.join(project_root, 'node_modules')
                    if not os.path.exists(node_modules_path):
                        print(f"      âš ï¸  {build_framework.capitalize()} dependencies not installed", flush=True)
                        print(f"      ðŸ’¡ Run: cd {os.path.basename(project_root)} && npm install", flush=True)
                        return []
                    
                    # Check if artifacts exist from previous compilation
                    artifacts_dir = os.path.join(project_root, 'artifacts')
                    has_artifacts = os.path.exists(artifacts_dir) and os.listdir(artifacts_dir)
                    
                    if not has_artifacts:
                        print(f"      âš ï¸  No compiled artifacts found for {build_framework.capitalize()} project", flush=True)
                        print(f"      ðŸ”¨ Attempting to compile {build_framework.capitalize()} project...", flush=True)
                        
                        # Try to compile using our helper script (which needs to run outside sandbox)
                        compile_script = os.path.join(os.getcwd(), 'scripts', 'compile_hardhat_projects.sh')
                        try:
                            compile_result = subprocess.run(
                                ['/bin/bash', compile_script, project_root],
                                capture_output=True,
                                text=True,
                                timeout=180
                            )
                            
                            if compile_result.returncode == 0:
                                print(f"      âœ… {build_framework.capitalize()} compilation successful", flush=True)
                                has_artifacts = True
                                slither_target = project_root
                            else:
                                # Check for permission errors
                                if 'EPERM' in compile_result.stderr or 'permission denied' in compile_result.stderr.lower():
                                    print(f"      âŒ Compilation failed due to permission restrictions", flush=True)
                                    print(f"      ðŸ’¡ Manual compile needed: cd {project_root} && npx hardhat compile", flush=True)
                                else:
                                    print(f"      âš ï¸  Compilation failed: {compile_result.stderr[:200]}", flush=True)
                                
                                print(f"      âš ï¸  Falling back to standalone contract analysis...", flush=True)
                                build_framework = None
                                slither_target = contract_path
                        
                        except Exception as e:
                            print(f"      âš ï¸  Could not compile: {e}", flush=True)
                            print(f"      âš ï¸  Falling back to standalone contract analysis...", flush=True)
                            build_framework = None
                            slither_target = contract_path
                    else:
                        print(f"      âœ… Detected existing {build_framework.capitalize()} artifacts", flush=True)
                        # For Hardhat/Truffle, analyze individual contract to avoid framework compilation issues
                        print(f"      ðŸ’¡ Analyzing individual contract to avoid permission issues", flush=True)
                        slither_target = contract_path
                        # Clear build_framework so we use solc directly
                        build_framework = None
                else:
                    slither_target = project_root
            else:
                slither_target = contract_path
            
            cmd = [
                slither_cmd,
                slither_target,
                '--json', '-',
                '--exclude-dependencies',
                '--exclude-informational'
            ]
            
            # Only force framework compilation if we're analyzing a standalone contract
            # For Hardhat/Truffle projects, DON'T use the framework - it causes permission issues
            # Instead, use solc-standard-json for better compatibility
            if build_framework in ['hardhat', 'truffle'] and project_root:
                # Use solc-standard-json to avoid Hardhat parsing issues and permission errors
                cmd.append('--solc-standard-json')
                print(f"      ðŸ’¡ Using solc-standard-json to avoid Hardhat/Truffle parsing issues", flush=True)
            elif build_framework and build_framework in ['foundry']:
                # Foundry works fine with force framework
                cmd.extend(['--compile-force-framework', build_framework])
            
            # Add --solc flag if we found a binary
            if solc_binary:
                cmd.insert(1, '--solc')
                cmd.insert(2, solc_binary)

            # For framework projects, run from project root; otherwise from contract dir
            if project_root:
                contract_cwd = project_root
            else:
                contract_cwd = os.path.dirname(os.path.abspath(contract_path)) or None
            
            # Clean progress indicator
            framework_str = f" ({build_framework})" if build_framework else ""
            print(f"      â³ Running Slither analysis{framework_str}...", flush=True)
            print(f"         Compiling project, please wait", end='', flush=True)
            
            # Show periodic progress during long-running compilation
            import threading
            import sys
            
            analysis_complete = threading.Event()
            
            def show_progress():
                """Show progress dots while analysis runs."""
                dots = 0
                while not analysis_complete.is_set():
                    time.sleep(5)  # Every 5 seconds
                    if not analysis_complete.is_set():
                        dots += 1
                        sys.stdout.write('.')
                        sys.stdout.flush()
                        if dots % 2 == 0:  # Every 10 seconds
                            print(f" {dots*5}s", end='', flush=True)
            
            progress_thread = threading.Thread(target=show_progress, daemon=True)
            progress_thread.start()
            
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=300,
                    env=env,
                    cwd=contract_cwd
                )
            finally:
                analysis_complete.set()
                progress_thread.join(timeout=1)
                print()  # New line after dots
            
            # Log detailed output to file
            with open(log_file, 'w') as f:
                f.write(f"Command: {' '.join(cmd)}\n")
                f.write(f"Working directory: {contract_cwd}\n")
                f.write(f"Exit code: {result.returncode}\n\n")
                f.write("=== STDOUT ===\n")
                f.write(result.stdout)
                f.write("\n\n=== STDERR ===\n")
                f.write(result.stderr)

            # Handle output cleanly
            if result.returncode != 0 and result.returncode != 255:
                # Non-zero exit (but 255 is normal for slither when findings exist)
                
                # Check if this is a compilation/permission error  
                stdout_empty = not result.stdout or result.stdout.strip() == ''
                stderr_lines = result.stderr.strip().split('\n') if result.stderr else []
                stderr_minimal = len(stderr_lines) <= 3 and any('pkg_resources' in line for line in stderr_lines)
                is_empty_output = stdout_empty and (not result.stderr or stderr_minimal)
                
                if is_empty_output and result.returncode == 1:
                    # Slither compilation failed - likely due to import resolution or permissions
                    print(f"      âš ï¸  Slither compilation failed (exit code {result.returncode})", flush=True)
                    print(f"      ðŸ“‹ Full output logged to: {log_file}", flush=True)
                    
                    # For Hardhat/Truffle, give specific guidance
                    if project_root and os.path.exists(os.path.join(project_root, 'hardhat.config.js')) or \
                       os.path.exists(os.path.join(project_root, 'hardhat.config.ts')):
                        print(f"      ðŸ’¡ KNOWN ISSUE: Hardhat projects can't be analyzed via Slither in sandboxed environments", flush=True)
                        print(f"      ðŸ’¡ Workaround: Pre-compile before audit:", flush=True)
                        print(f"           cd {project_root}", flush=True)
                        print(f"           npx hardhat compile", flush=True)
                    
                    print(f"      âœ… Continuing with enhanced pattern-based detectors (often more accurate anyway)...", flush=True)
                    return []  # Skip Slither gracefully
                
                print(f"      âš ï¸  Slither analysis encountered issues (exit code: {result.returncode})", flush=True)
                print(f"      ðŸ“‹ Full output logged to: {log_file}", flush=True)
                
                # Check for common errors in stderr
                if result.stderr:
                    stderr_lower = result.stderr.lower()
                    
                    # Check for permission/sandbox issues
                    if 'eperm' in stderr_lower or 'permission denied' in stderr_lower or 'operation not permitted' in stderr_lower:
                        print(f"      âŒ File permission error detected - likely sandbox restriction", flush=True)
                        print(f"      ðŸ’¡ Hint: Hardhat/Truffle projects need write access to cache directories", flush=True)
                        print(f"      ðŸ’¡ This is a known limitation - Slither analysis will be skipped", flush=True)
                        print(f"      âœ… Continuing with enhanced pattern-based detectors...", flush=True)
                        return []  # Skip Slither gracefully
                    elif 'compilation failed' in stderr_lower or 'solcexception' in stderr_lower:
                        print(f"      ðŸ’¡ Hint: Contract may have compilation errors", flush=True)
                    elif 'not supported by hardhat' in stderr_lower or 'node.js' in stderr_lower:
                        print(f"      ðŸ’¡ Hint: Node.js version issue detected", flush=True)
                        print(f"      ðŸ’¡ Try: source ~/.nvm/nvm.sh && nvm use", flush=True)
                    elif 'not found' in stderr_lower:
                        print(f"      ðŸ’¡ Hint: Missing dependencies or incorrect path", flush=True)
                    elif 'node_modules' in stderr_lower:
                        print(f"      ðŸ’¡ Hint: Dependencies may not be installed (npm install)", flush=True)
                
                # Check stdout for errors too (Hardhat sometimes writes there)
                if result.stdout and not result.stdout.strip().startswith('{'):
                    stdout_lower = result.stdout.lower()
                    if 'eperm' in stdout_lower or 'permission denied' in stdout_lower or 'operation not permitted' in stdout_lower:
                        print(f"      âŒ File permission error detected - likely sandbox restriction", flush=True)
                        print(f"      ðŸ’¡ Hint: Hardhat/Truffle projects need write access to cache directories", flush=True)
                        print(f"      ðŸ’¡ This is a known limitation - Slither analysis will be skipped", flush=True)
                        print(f"      âœ… Continuing with enhanced pattern-based detectors...", flush=True)
                        return []  # Skip Slither gracefully

            # Try to parse JSON output - slither may write to either stdout or mixed output
            # and exit with code 0, 1, or 255 but still produce valid JSON
            json_output = result.stdout
            # If stdout doesn't start with JSON, attempt to extract a balanced JSON object
            if not (json_output and json_output.strip().startswith('{')):
                candidate_streams = []
                if result.stdout:
                    candidate_streams.append(result.stdout)
                if result.stderr:
                    candidate_streams.append(result.stderr)

                for stream in candidate_streams:
                    # Find the first JSON object by locating a balanced top-level {...}
                    brace_stack = 0
                    start_idx = -1
                    found = ''
                    for idx, ch in enumerate(stream):
                        if ch == '{':
                            if brace_stack == 0:
                                start_idx = idx
                            brace_stack += 1
                        elif ch == '}':
                            if brace_stack > 0:
                                brace_stack -= 1
                                if brace_stack == 0 and start_idx != -1:
                                    candidate = stream[start_idx:idx+1]
                                    found = candidate
                                    break
                    if found.strip().startswith('{'):
                        json_output = found
                        break
            
            try:
                if json_output.strip().startswith('{'):
                    data = json.loads(json_output)
                    findings = self._parse_slither_json_output(data)
                    
                    # Filter findings to only include the target contract if we analyzed entire project
                    if build_framework in ['hardhat', 'truffle'] and project_root:
                        original_count = len(findings)
                        contract_basename = os.path.basename(contract_path)
                        findings = [
                            f for f in findings 
                            if contract_basename in f.get('description', '') or 
                               contract_basename in str(f.get('elements', []))
                        ]
                        if original_count > len(findings):
                            print(f"      ðŸ” Filtered to {len(findings)} findings for {contract_basename}", flush=True)
                    
                    if findings:
                        # Show clean summary
                        severity_counts = {}
                        for f in findings:
                            sev = f.get('severity', 'Unknown')
                            severity_counts[sev] = severity_counts.get(sev, 0) + 1
                        severity_str = ", ".join([f"{count} {sev}" for sev, count in sorted(severity_counts.items())])
                        print(f"      âœ… Slither: {len(findings)} findings ({severity_str})", flush=True)
                    else:
                        print(f"      âœ… Slither: No issues found", flush=True)
                    return findings
                else:
                    print(f"      âš ï¸  Slither: No JSON output received", flush=True)
                    print(f"      ðŸ“‹ Full output logged to: {log_file}", flush=True)
            except json.JSONDecodeError as e:
                print(f"      âš ï¸  Slither: Could not parse output", flush=True)
                print(f"      ðŸ“‹ Full output logged to: {log_file}", flush=True)
            
            # Return empty list if we couldn't parse JSON
            # The rest of the pipeline (enhanced detectors + AI) will still analyze the contract
            return []

        except Exception as e:
            import logging
            logging.debug(f"Slither CLI analysis failed: {e}")
            print(f"      âš ï¸  Slither: Error during analysis", flush=True)
            # Don't crash - let other analysis methods handle it
            return []

    def _parse_slither_json_output(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Parse Slither JSON output into standardized format."""
        findings = []

        try:
            # Handle different slither JSON formats
            # Newer versions have: {"results": {"detectors": [...]}}
            # Older versions have: {"detectors": [...]}
            detectors = data.get('results', {}).get('detectors', [])
            if not detectors:
                detectors = data.get('detectors', [])

            for detector in detectors:
                detector_type = detector.get('check', 'unknown')
                impact = detector.get('impact', 'Medium')
                description = detector.get('description', '')

                # Extract results/elements
                results = detector.get('results', [])
                if not results:
                    results = detector.get('elements', [])

                # Only add if there are actual results/elements
                if results:
                    for result in results:
                        line_number = 0
                        if isinstance(result, dict):
                            source_mapping = result.get('source_mapping', {})
                            if isinstance(source_mapping, dict):
                                lines = source_mapping.get('lines', [])
                                if lines:
                                    line_number = lines[0]
                                else:
                                    line_number = result.get('line', 0)

                        findings.append({
                            'type': detector_type,
                            'severity': impact,
                            'description': description,
                            'line': line_number
                        })
                else:
                    # Add finding even without specific elements (for informational issues)
                    findings.append({
                        'type': detector_type,
                        'severity': impact,
                        'description': description,
                        'line': 0
                    })

        except Exception as e:
            import logging
            logging.debug(f"Error parsing Slither JSON: {e}")

        return findings
